{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException,ElementNotInteractableException,TimeoutException\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url = 'https://www.dailypioneer.com/searchlist.php?yr=2015&mn=6&page=1#/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for i in range(48):\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='pagingList']/ul/li/a\"):\n",
    "        urls.append(j.get_attribute(\"href\"))\n",
    "    driver.find_element_by_class_name(\"pnext\").click()\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_new = urls[13:14]+urls[1:11]+urls[15:25]+urls[29:39]+urls[43:53]+urls[57:67]+urls[71:81]+urls[85:95]+urls[99:109]+urls[113:123]+urls[127:137]+urls[141:151]+urls[155:165]+urls[169:179]+urls[183:193]+urls[197:207]+urls[211:221]+urls[225:235]+urls[239:249]+urls[253:263]+urls[267:277]+urls[281:291]+urls[295:305]+urls[309:319]+urls[323:333]+urls[337:347]+urls[351:361]+urls[365:375]+urls[379:389]+urls[393:403]+urls[407:417]+urls[421:431]+urls[435:445]+urls[449:459]+urls[463:473]+urls[477:487]+urls[491:501]+urls[505:515]+urls[519:529]+urls[533:543]+urls[547:557]+urls[561:571]+urls[575:585]+urls[589:599]+urls[603:613]+urls[617:627]+urls[631:641]+urls[645:655]+urls[659:669]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls1=[]\n",
    "for j in driver.find_elements_by_id(482):\n",
    "    urls1.append(j.get_attribute(\"href\"))\n",
    "for j in driver.find_elements_by_id(483):\n",
    "    urls1.append(j.get_attribute(\"href\"))    \n",
    "for j in driver.find_elements_by_id(484):\n",
    "    urls1.append(j.get_attribute(\"href\"))       \n",
    "for j in driver.find_elements_by_id(485):\n",
    "    urls1.append(j.get_attribute(\"href\"))    \n",
    "for j in driver.find_elements_by_id(486):\n",
    "    urls1.append(j.get_attribute(\"href\"))    \n",
    "for j in driver.find_elements_by_id(487):\n",
    "    urls1.append(j.get_attribute(\"href\")) \n",
    "for j in driver.find_elements_by_id(488):\n",
    "    urls1.append(j.get_attribute(\"href\"))\n",
    "for j in driver.find_elements_by_id(489):\n",
    "    urls1.append(j.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_sum = urls_new + urls1\n",
    "len(url_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({})\n",
    "df[\"url\"] = url_sum\n",
    "df.to_csv(\"page_urls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"page_urls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_title=[]\n",
    "for i in df.url:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"col-12\"]/h2/a|//div[@class=\"col-12\"]/h2/a|//ul[@class=\"list-unstyled\"]/li[2]/h3/a|//div[@class=\"BigNews\"]/h2/a'):\n",
    "        url_title.append(j.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3797"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({})\n",
    "df[\"url\"] = url_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('scraped_urls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scraping news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('scraped_urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1=[]\n",
    "author1=[]\n",
    "vertical1=[]\n",
    "headline1=[]\n",
    "description1=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.url[0:1000]:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        a = driver.find_element_by_xpath(\"//div[@class='newsInfo']/span\")\n",
    "        date1.append(a.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        date1.append(' ')\n",
    "        \n",
    "    try:\n",
    "        b = driver.find_element_by_xpath(\"//span[@itemprop='author']|//div[@class='newsInfo']/span[3]\")\n",
    "        author1.append(b.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        author1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        d = driver.find_element_by_xpath(\"//div[@class='col-12']/h2|//h2[@itemprop='headline']\")\n",
    "        headline1.append(d.text) \n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        headline1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        e = driver.find_element_by_id(\"printArea\")\n",
    "        description1.append(e.text) \n",
    "    except NoSuchElementException:\n",
    "        description1.append(' ')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({})\n",
    "df1[\"Date\"] = date1\n",
    "df1[\"Author\"] = author1\n",
    "df1[\"Headline\"] = headline1\n",
    "df1[\"Description\"] = description1\n",
    "df1.to_csv(\"pioneer_news1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.url[1000:1500]:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        a = driver.find_element_by_xpath(\"//div[@class='newsInfo']/span\")\n",
    "        date1.append(a.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        date1.append(' ')\n",
    "        \n",
    "    try:\n",
    "        b = driver.find_element_by_xpath(\"//span[@itemprop='author']|//div[@class='newsInfo']/span[3]\")\n",
    "        author1.append(b.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        author1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        d = driver.find_element_by_xpath(\"//div[@class='col-12']/h2|//h2[@itemprop='headline']\")\n",
    "        headline1.append(d.text) \n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        headline1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        e = driver.find_element_by_id(\"printArea\")\n",
    "        description1.append(e.text) \n",
    "    except NoSuchElementException:\n",
    "        description1.append(' ')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({})\n",
    "df2[\"Date\"] = date1\n",
    "df2[\"Author\"] = author1\n",
    "df2[\"Headline\"] = headline1\n",
    "df2[\"Description\"] = description1\n",
    "df2.to_csv(\"pioneer_news2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.url[1500:2000]:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        a = driver.find_element_by_xpath(\"//div[@class='newsInfo']/span\")\n",
    "        date1.append(a.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        date1.append(' ')\n",
    "        \n",
    "    try:\n",
    "        b = driver.find_element_by_xpath(\"//span[@itemprop='author']|//div[@class='newsInfo']/span[3]\")\n",
    "        author1.append(b.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        author1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        d = driver.find_element_by_xpath(\"//div[@class='col-12']/h2|//h2[@itemprop='headline']\")\n",
    "        headline1.append(d.text) \n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        headline1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        e = driver.find_element_by_id(\"printArea\")\n",
    "        description1.append(e.text) \n",
    "    except NoSuchElementException:\n",
    "        description1.append(' ')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({})\n",
    "df3[\"Date\"] = date1\n",
    "df3[\"Author\"] = author1\n",
    "df3[\"Headline\"] = headline1\n",
    "df3[\"Description\"] = description1\n",
    "df3.to_csv(\"pioneer_news3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.url[2000:3000]:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        a = driver.find_element_by_xpath(\"//div[@class='newsInfo']/span\")\n",
    "        date1.append(a.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        date1.append(' ')\n",
    "        \n",
    "    try:\n",
    "        b = driver.find_element_by_xpath(\"//span[@itemprop='author']|//div[@class='newsInfo']/span[3]\")\n",
    "        author1.append(b.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        author1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        d = driver.find_element_by_xpath(\"//div[@class='col-12']/h2|//h2[@itemprop='headline']\")\n",
    "        headline1.append(d.text) \n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        headline1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        e = driver.find_element_by_id(\"printArea\")\n",
    "        description1.append(e.text) \n",
    "    except NoSuchElementException:\n",
    "        description1.append(' ')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({})\n",
    "df4[\"Date\"] = date1[500:]\n",
    "df4[\"Author\"] = author1[500:]\n",
    "df4[\"Headline\"] = headline1[500:]\n",
    "df4[\"Description\"] = description1[500:]\n",
    "df4.to_csv(\"pioneer_news4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.url[3000:3500]:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        a = driver.find_element_by_xpath(\"//div[@class='newsInfo']/span\")\n",
    "        date1.append(a.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        date1.append(' ')\n",
    "        \n",
    "    try:\n",
    "        b = driver.find_element_by_xpath(\"//span[@itemprop='author']|//div[@class='newsInfo']/span[3]\")\n",
    "        author1.append(b.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        author1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        d = driver.find_element_by_xpath(\"//div[@class='col-12']/h2|//h2[@itemprop='headline']\")\n",
    "        headline1.append(d.text) \n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        headline1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        e = driver.find_element_by_id(\"printArea\")\n",
    "        description1.append(e.text) \n",
    "    except NoSuchElementException:\n",
    "        description1.append(' ')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame({})\n",
    "df5[\"Date\"] = date1\n",
    "df5[\"Author\"] = author1\n",
    "df5[\"Headline\"] = headline1\n",
    "df5[\"Description\"] = description1\n",
    "df5.to_csv(\"pioneer_news5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.url[3500:]:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        a = driver.find_element_by_xpath(\"//div[@class='newsInfo']/span\")\n",
    "        date1.append(a.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        date1.append(' ')\n",
    "        \n",
    "    try:\n",
    "        b = driver.find_element_by_xpath(\"//span[@itemprop='author']|//div[@class='newsInfo']/span[3]\")\n",
    "        author1.append(b.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        author1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        d = driver.find_element_by_xpath(\"//div[@class='col-12']/h2|//h2[@itemprop='headline']\")\n",
    "        headline1.append(d.text) \n",
    "            \n",
    "    except NoSuchElementException:\n",
    "        headline1.append(' ')\n",
    "    \n",
    "    try:\n",
    "        e = driver.find_element_by_id(\"printArea\")\n",
    "        description1.append(e.text) \n",
    "    except NoSuchElementException:\n",
    "        description1.append(' ')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.DataFrame({})\n",
    "df6[\"Date\"] = date1[500:]\n",
    "df6[\"Author\"] = author1[500:]\n",
    "df6[\"Headline\"] = headline1[500:]\n",
    "df6[\"Description\"] = description1[500:]\n",
    "df6.to_csv(\"pioneer_news6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat all the news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Author</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday, 30 June 2015</td>\n",
       "      <td>Sandhya Jain</td>\n",
       "      <td>IPl mess: Setting the cat among the pigeons</td>\n",
       "      <td>The way out of the mess lalit Modi has raked u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday, 30 June 2015</td>\n",
       "      <td>Kushan Mitra</td>\n",
       "      <td>Debating cut-offs versus quality</td>\n",
       "      <td>The inexorable rise in cut-offs point to the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tuesday, 30 June 2015</td>\n",
       "      <td>PNS</td>\n",
       "      <td>Azam says police to take tough step agst socia...</td>\n",
       "      <td>Showing his annoyance over police investigatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tuesday, 30 June 2015</td>\n",
       "      <td>Pioneer News Service</td>\n",
       "      <td>Ranjan directs officials to take communal matt...</td>\n",
       "      <td>Chief Secretary, Alok Ranjan directed the seni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday, 30 June 2015</td>\n",
       "      <td>PNS</td>\n",
       "      <td>BJP stages protest agsnt state Govt for worsen...</td>\n",
       "      <td>On the first day of the two day stir, the Bhar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>292</td>\n",
       "      <td>Monday, 01 June 2015</td>\n",
       "      <td>PNS</td>\n",
       "      <td>For me executing OROP is service to nation: Modi</td>\n",
       "      <td>Reiterating his commitment on One-Rank, One-Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>293</td>\n",
       "      <td>Monday, 01 June 2015</td>\n",
       "      <td>Kestur Vasuki</td>\n",
       "      <td>King Cobra's death turns into red light for tr...</td>\n",
       "      <td>The Aurad-Sadashivgad State Highway (SH-34) pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>Monday, 01 June 2015</td>\n",
       "      <td>Pramod Kumar Singh</td>\n",
       "      <td>No hot dogs, rules Delhi Police till heat subs...</td>\n",
       "      <td>Intense heat is causing discomfort not only to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>295</td>\n",
       "      <td>Monday, 01 June 2015</td>\n",
       "      <td>PTI</td>\n",
       "      <td>Don't yet know about my role in advisory commi...</td>\n",
       "      <td>He is still not clear about his role in the BC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>296</td>\n",
       "      <td>Monday, 01 June 2015</td>\n",
       "      <td>IANS</td>\n",
       "      <td>Kendall Jenner wants to throw her phone away</td>\n",
       "      <td>Model Kendall Jenner is frustrated with her ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3797 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                   Date                Author  \\\n",
       "0             0  Tuesday, 30 June 2015          Sandhya Jain   \n",
       "1             1  Tuesday, 30 June 2015          Kushan Mitra   \n",
       "2             2  Tuesday, 30 June 2015                   PNS   \n",
       "3             3  Tuesday, 30 June 2015  Pioneer News Service   \n",
       "4             4  Tuesday, 30 June 2015                   PNS   \n",
       "..          ...                    ...                   ...   \n",
       "292         292   Monday, 01 June 2015                   PNS   \n",
       "293         293   Monday, 01 June 2015         Kestur Vasuki   \n",
       "294         294   Monday, 01 June 2015    Pramod Kumar Singh   \n",
       "295         295   Monday, 01 June 2015                   PTI   \n",
       "296         296   Monday, 01 June 2015                  IANS   \n",
       "\n",
       "                                              Headline  \\\n",
       "0          IPl mess: Setting the cat among the pigeons   \n",
       "1                     Debating cut-offs versus quality   \n",
       "2    Azam says police to take tough step agst socia...   \n",
       "3    Ranjan directs officials to take communal matt...   \n",
       "4    BJP stages protest agsnt state Govt for worsen...   \n",
       "..                                                 ...   \n",
       "292   For me executing OROP is service to nation: Modi   \n",
       "293  King Cobra's death turns into red light for tr...   \n",
       "294  No hot dogs, rules Delhi Police till heat subs...   \n",
       "295  Don't yet know about my role in advisory commi...   \n",
       "296       Kendall Jenner wants to throw her phone away   \n",
       "\n",
       "                                           Description  \n",
       "0    The way out of the mess lalit Modi has raked u...  \n",
       "1    The inexorable rise in cut-offs point to the f...  \n",
       "2    Showing his annoyance over police investigatio...  \n",
       "3    Chief Secretary, Alok Ranjan directed the seni...  \n",
       "4    On the first day of the two day stir, the Bhar...  \n",
       "..                                                 ...  \n",
       "292  Reiterating his commitment on One-Rank, One-Pe...  \n",
       "293  The Aurad-Sadashivgad State Highway (SH-34) pa...  \n",
       "294  Intense heat is causing discomfort not only to...  \n",
       "295  He is still not clear about his role in the BC...  \n",
       "296  Model Kendall Jenner is frustrated with her ha...  \n",
       "\n",
       "[3797 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.read_csv(\"pioneer_news6.csv\")\n",
    "df1 = pd.read_csv(\"pioneer_news5.csv\")\n",
    "df2 = pd.read_csv(\"pioneer_news4.csv\")\n",
    "df3 = pd.read_csv(\"pioneer_news3.csv\")\n",
    "df4 = pd.read_csv(\"pioneer_news2.csv\")\n",
    "df5 = pd.read_csv(\"pioneer_news1.csv\")\n",
    "\n",
    "\n",
    "news = pd.concat([df5,df4,df3,df2,df1,df0],axis=0)\n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.to_csv(\"THE PIONEER.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
